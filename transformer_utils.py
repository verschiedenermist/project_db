# -*- coding: utf-8 -*-
"""transformer_utils

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1reqxgzkhHSoygPXinN4oD_TcIhZa7cBQ
"""

from transformers import AutoTokenizer, AutoModel
import torch

tokenizer = AutoTokenizer.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")
model = AutoModel.from_pretrained("sentence-transformers/all-MiniLM-L6-v2")


def get_embedding(text: str) -> list:
    '''
    Получение эмбеддинга текста с использованием модели из transformers
    '''
    # токенизация текста
    inputs = tokenizer(text, return_tensors="pt", truncation=True, padding=True, max_length=512)

    # получение эмбеддингов
    with torch.no_grad():
        outputs = model(**inputs)

    # извлечение эмбеддингов из последнего слоя
    embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()

    return embeddings.tolist()